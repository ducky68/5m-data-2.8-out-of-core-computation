{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-World Polars Data Analysis Exercise\n",
    "\n",
    "## Overview\n",
    "Welcome to this comprehensive Polars data analysis exercise! You'll work as a data analyst for **Global Analytics Inc.**, a consulting firm that helps organizations make data-driven decisions. Your task is to analyze multiple real-world datasets to provide insights for different clients.\n",
    "\n",
    "**Note**: This exercise uses sample datasets that mirror the structure of real-world data from sources like Our World in Data (COVID-19), Yahoo Finance (stocks), retail transaction data, and World Bank (population data).\n",
    "\n",
    "## Business Scenarios\n",
    "\n",
    "### Scenario 1: Public Health Analysis for World Health Organization\n",
    "**Client**: World Health Organization (WHO)  \n",
    "**Dataset**: COVID-19 global data  \n",
    "**Business Question**: Analyze global COVID-19 pandemic trends to inform public health policy decisions.\n",
    "\n",
    "### Scenario 2: Investment Analysis for PrimeTech Capital\n",
    "**Client**: PrimeTech Capital (Investment Firm)  \n",
    "**Dataset**: Stock market data for major tech companies  \n",
    "**Business Question**: Evaluate technology stock performance to guide investment strategies.\n",
    "\n",
    "### Scenario 3: Retail Strategy for SuperMart Chain\n",
    "**Client**: SuperMart (Retail Chain)  \n",
    "**Dataset**: Sales transaction data  \n",
    "**Business Question**: Optimize product mix and identify growth opportunities.\n",
    "\n",
    "### Scenario 4: Market Research for GlobalTech Corp\n",
    "**Client**: GlobalTech Corp (Technology Company)  \n",
    "**Dataset**: Global population and demographic data  \n",
    "**Business Question**: Identify target markets for expansion based on population trends.\n",
    "\n",
    "---\n",
    "\n",
    "## Getting Started\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Load all datasets\n",
    "covid_df = pl.read_csv(\"covid_global_data.csv\")\n",
    "stocks_df = pl.read_csv(\"tech_stocks_data.csv\") \n",
    "sales_df = pl.read_csv(\"supermart_sales_data.csv\")\n",
    "population_df = pl.read_csv(\"global_population_data.csv\")\n",
    "company_df = pl.read_csv(\"company_info_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PART 1: Data Exploration and Basic Operations\n",
    "\n",
    "### Exercise 1.1: Creating and Inspecting DataFrames\n",
    "\n",
    "**Business Context**: Before analyzing any dataset, you need to understand its structure and content.\n",
    "\n",
    "**Tasks**:\n",
    "1. Display the shape and basic info for each dataset\n",
    "2. Show the first 5 rows of each dataset\n",
    "3. Display column names and data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COVID DataFrame Shape: (14610, 6)\n",
      "COVID DataFrame Columns: ['date', 'country', 'new_cases', 'new_deaths', 'total_cases', 'total_deaths']\n",
      "COVID DataFrame Head:\n",
      "shape: (5, 6)\n",
      "┌────────────┬───────────────┬───────────┬────────────┬─────────────┬──────────────┐\n",
      "│ date       ┆ country       ┆ new_cases ┆ new_deaths ┆ total_cases ┆ total_deaths │\n",
      "│ ---        ┆ ---           ┆ ---       ┆ ---        ┆ ---         ┆ ---          │\n",
      "│ str        ┆ str           ┆ f64       ┆ f64        ┆ f64         ┆ f64          │\n",
      "╞════════════╪═══════════════╪═══════════╪════════════╪═════════════╪══════════════╡\n",
      "│ 2020-01-01 ┆ United States ┆ 47.0      ┆ 0.0        ┆ 47.0        ┆ 0.0          │\n",
      "│ 2020-01-02 ┆ United States ┆ 10.0      ┆ 0.0        ┆ 57.0        ┆ 0.0          │\n",
      "│ 2020-01-03 ┆ United States ┆ 39.0      ┆ 0.0        ┆ 96.0        ┆ 0.0          │\n",
      "│ 2020-01-04 ┆ United States ┆ 10.0      ┆ 0.0        ┆ 106.0       ┆ 0.0          │\n",
      "│ 2020-01-05 ┆ United States ┆ 25.0      ┆ 2.0        ┆ 131.0       ┆ 2.0          │\n",
      "└────────────┴───────────────┴───────────┴────────────┴─────────────┴──────────────┘\n",
      "\n",
      "==================================================\n",
      "\n",
      "Stocks DataFrame Shape: (8344, 7)\n",
      "Stocks DataFrame Columns: ['date', 'symbol', 'open', 'high', 'low', 'close', 'volume']\n",
      "Stocks DataFrame Head:\n",
      "shape: (5, 7)\n",
      "┌────────────┬────────┬────────┬────────┬────────┬────────┬──────────┐\n",
      "│ date       ┆ symbol ┆ open   ┆ high   ┆ low    ┆ close  ┆ volume   │\n",
      "│ ---        ┆ ---    ┆ ---    ┆ ---    ┆ ---    ┆ ---    ┆ ---      │\n",
      "│ str        ┆ str    ┆ f64    ┆ f64    ┆ f64    ┆ f64    ┆ i64      │\n",
      "╞════════════╪════════╪════════╪════════╪════════╪════════╪══════════╡\n",
      "│ 2020-01-01 ┆ AAPL   ┆ 453.31 ┆ 464.79 ┆ 451.66 ┆ 456.22 ┆ 33335151 │\n",
      "│ 2020-01-02 ┆ AAPL   ┆ 449.22 ┆ 452.34 ┆ 443.46 ┆ 450.87 ┆ 18852110 │\n",
      "│ 2020-01-03 ┆ AAPL   ┆ 462.21 ┆ 462.56 ┆ 451.64 ┆ 459.14 ┆ 2285651  │\n",
      "│ 2020-01-06 ┆ AAPL   ┆ 475.14 ┆ 481.87 ┆ 467.84 ┆ 468.79 ┆ 7444385  │\n",
      "│ 2020-01-07 ┆ AAPL   ┆ 468.88 ┆ 468.94 ┆ 464.1  ┆ 466.54 ┆ 44543554 │\n",
      "└────────────┴────────┴────────┴────────┴────────┴────────┴──────────┘\n",
      "\n",
      "==================================================\n",
      "\n",
      "Sales DataFrame Shape: (5000, 16)\n",
      "Sales DataFrame Columns: ['order_id', 'order_date', 'ship_date', 'ship_mode', 'customer_id', 'customer_name', 'segment', 'region', 'state', 'category', 'sub_category', 'product_name', 'sales', 'quantity', 'discount', 'profit']\n",
      "Sales DataFrame Head:\n",
      "shape: (5, 16)\n",
      "┌──────────┬────────────┬────────────┬────────────────┬───┬─────────┬──────────┬──────────┬────────┐\n",
      "│ order_id ┆ order_date ┆ ship_date  ┆ ship_mode      ┆ … ┆ sales   ┆ quantity ┆ discount ┆ profit │\n",
      "│ ---      ┆ ---        ┆ ---        ┆ ---            ┆   ┆ ---     ┆ ---      ┆ ---      ┆ ---    │\n",
      "│ str      ┆ str        ┆ str        ┆ str            ┆   ┆ f64     ┆ i64      ┆ f64      ┆ f64    │\n",
      "╞══════════╪════════════╪════════════╪════════════════╪═══╪═════════╪══════════╪══════════╪════════╡\n",
      "│ ORD-1000 ┆ 2022-03-11 ┆ 2022-03-21 ┆ Second Class   ┆ … ┆ 1075.08 ┆ 2        ┆ 0.0      ┆ 203.73 │\n",
      "│ ORD-1001 ┆ 2019-12-20 ┆ 2019-12-29 ┆ First Class    ┆ … ┆ 9265.63 ┆ 10       ┆ 0.0      ┆ 508.96 │\n",
      "│ ORD-1002 ┆ 2021-02-28 ┆ 2021-03-03 ┆ Same Day       ┆ … ┆ 1309.0  ┆ 9        ┆ 0.0      ┆ 198.07 │\n",
      "│ ORD-1003 ┆ 2021-09-17 ┆ 2021-09-27 ┆ Standard Class ┆ … ┆ 3012.36 ┆ 4        ┆ 0.0      ┆ 386.92 │\n",
      "│ ORD-1004 ┆ 2022-02-20 ┆ 2022-02-25 ┆ Same Day       ┆ … ┆ 2731.23 ┆ 5        ┆ 0.0      ┆ 709.41 │\n",
      "└──────────┴────────────┴────────────┴────────────────┴───┴─────────┴──────────┴──────────┴────────┘\n",
      "\n",
      "==================================================\n",
      "\n",
      "Population DataFrame Shape: (140, 4)\n",
      "Population DataFrame Columns: ['country_name', 'country_code', 'year', 'population']\n",
      "Population DataFrame Head:\n",
      "shape: (5, 4)\n",
      "┌───────────────┬──────────────┬──────┬──────────────┐\n",
      "│ country_name  ┆ country_code ┆ year ┆ population   │\n",
      "│ ---           ┆ ---          ┆ ---  ┆ ---          │\n",
      "│ str           ┆ str          ┆ i64  ┆ f64          │\n",
      "╞═══════════════╪══════════════╪══════╪══════════════╡\n",
      "│ United States ┆ UNI          ┆ 2010 ┆ 2.04078148e8 │\n",
      "│ United States ┆ UNI          ┆ 2011 ┆ 2.05670942e8 │\n",
      "│ United States ┆ UNI          ┆ 2012 ┆ 2.07276169e8 │\n",
      "│ United States ┆ UNI          ┆ 2013 ┆ 2.08893924e8 │\n",
      "│ United States ┆ UNI          ┆ 2014 ┆ null         │\n",
      "└───────────────┴──────────────┴──────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Hint: Use .shape, .head(), .columns, .dtypes\n",
    "print(\"COVID DataFrame Shape:\", covid_df.shape)\n",
    "print(\"COVID DataFrame Columns:\", covid_df.columns)\n",
    "print(\"COVID DataFrame Head:\")\n",
    "print(covid_df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Stocks DataFrame Shape:\", stocks_df.shape)\n",
    "print(\"Stocks DataFrame Columns:\", stocks_df.columns)\n",
    "print(\"Stocks DataFrame Head:\")\n",
    "print(stocks_df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Sales DataFrame Shape:\", sales_df.shape)\n",
    "print(\"Sales DataFrame Columns:\", sales_df.columns)\n",
    "print(\"Sales DataFrame Head:\")\n",
    "print(sales_df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Population DataFrame Shape:\", population_df.shape)\n",
    "print(\"Population DataFrame Columns:\", population_df.columns)\n",
    "print(\"Population DataFrame Head:\")\n",
    "print(population_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Functions**: Basic DataFrame inspection\n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 1.2: Selecting Columns and Rows\n",
    "\n",
    "**Business Context**: You need to focus on specific data points for your analysis.\n",
    "\n",
    "**Tasks**:\n",
    "1. From the COVID dataset, select only 'date', 'country', and 'new_cases' columns\n",
    "2. From the stocks dataset, select columns whose names contain \"e\" (like 'date', 'close')\n",
    "3. Select the first 100 rows from the sales dataset\n",
    "4. Select rows 50-100 from the population dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. COVID dataset - selected columns:\n",
      "shape: (5, 3)\n",
      "┌────────────┬───────────────┬───────────┐\n",
      "│ date       ┆ country       ┆ new_cases │\n",
      "│ ---        ┆ ---           ┆ ---       │\n",
      "│ str        ┆ str           ┆ f64       │\n",
      "╞════════════╪═══════════════╪═══════════╡\n",
      "│ 2020-01-01 ┆ United States ┆ 47.0      │\n",
      "│ 2020-01-02 ┆ United States ┆ 10.0      │\n",
      "│ 2020-01-03 ┆ United States ┆ 39.0      │\n",
      "│ 2020-01-04 ┆ United States ┆ 10.0      │\n",
      "│ 2020-01-05 ┆ United States ┆ 25.0      │\n",
      "└────────────┴───────────────┴───────────┘\n",
      "Shape: (14610, 3)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Stock columns containing 'e': ['date', 'open', 'close', 'volume']\n",
      "2. Stocks dataset - columns containing 'e':\n",
      "shape: (5, 4)\n",
      "┌────────────┬────────┬────────┬──────────┐\n",
      "│ date       ┆ open   ┆ close  ┆ volume   │\n",
      "│ ---        ┆ ---    ┆ ---    ┆ ---      │\n",
      "│ str        ┆ f64    ┆ f64    ┆ i64      │\n",
      "╞════════════╪════════╪════════╪══════════╡\n",
      "│ 2020-01-01 ┆ 453.31 ┆ 456.22 ┆ 33335151 │\n",
      "│ 2020-01-02 ┆ 449.22 ┆ 450.87 ┆ 18852110 │\n",
      "│ 2020-01-03 ┆ 462.21 ┆ 459.14 ┆ 2285651  │\n",
      "│ 2020-01-06 ┆ 475.14 ┆ 468.79 ┆ 7444385  │\n",
      "│ 2020-01-07 ┆ 468.88 ┆ 466.54 ┆ 44543554 │\n",
      "└────────────┴────────┴────────┴──────────┘\n",
      "Shape: (8344, 4)\n",
      "\n",
      "==================================================\n",
      "\n",
      "3. Sales dataset - first 100 rows:\n",
      "shape: (5, 16)\n",
      "┌──────────┬────────────┬────────────┬────────────────┬───┬─────────┬──────────┬──────────┬────────┐\n",
      "│ order_id ┆ order_date ┆ ship_date  ┆ ship_mode      ┆ … ┆ sales   ┆ quantity ┆ discount ┆ profit │\n",
      "│ ---      ┆ ---        ┆ ---        ┆ ---            ┆   ┆ ---     ┆ ---      ┆ ---      ┆ ---    │\n",
      "│ str      ┆ str        ┆ str        ┆ str            ┆   ┆ f64     ┆ i64      ┆ f64      ┆ f64    │\n",
      "╞══════════╪════════════╪════════════╪════════════════╪═══╪═════════╪══════════╪══════════╪════════╡\n",
      "│ ORD-1000 ┆ 2022-03-11 ┆ 2022-03-21 ┆ Second Class   ┆ … ┆ 1075.08 ┆ 2        ┆ 0.0      ┆ 203.73 │\n",
      "│ ORD-1001 ┆ 2019-12-20 ┆ 2019-12-29 ┆ First Class    ┆ … ┆ 9265.63 ┆ 10       ┆ 0.0      ┆ 508.96 │\n",
      "│ ORD-1002 ┆ 2021-02-28 ┆ 2021-03-03 ┆ Same Day       ┆ … ┆ 1309.0  ┆ 9        ┆ 0.0      ┆ 198.07 │\n",
      "│ ORD-1003 ┆ 2021-09-17 ┆ 2021-09-27 ┆ Standard Class ┆ … ┆ 3012.36 ┆ 4        ┆ 0.0      ┆ 386.92 │\n",
      "│ ORD-1004 ┆ 2022-02-20 ┆ 2022-02-25 ┆ Same Day       ┆ … ┆ 2731.23 ┆ 5        ┆ 0.0      ┆ 709.41 │\n",
      "└──────────┴────────────┴────────────┴────────────────┴───┴─────────┴──────────┴──────────┴────────┘\n",
      "Shape: (100, 16)\n",
      "\n",
      "==================================================\n",
      "\n",
      "4. Population dataset - rows 50-100:\n",
      "shape: (5, 4)\n",
      "┌──────────────┬──────────────┬──────┬──────────────┐\n",
      "│ country_name ┆ country_code ┆ year ┆ population   │\n",
      "│ ---          ┆ ---          ┆ ---  ┆ ---          │\n",
      "│ str          ┆ str          ┆ i64  ┆ f64          │\n",
      "╞══════════════╪══════════════╪══════╪══════════════╡\n",
      "│ Indonesia    ┆ IND          ┆ 2017 ┆ 5.64002838e8 │\n",
      "│ Indonesia    ┆ IND          ┆ 2018 ┆ null         │\n",
      "│ Indonesia    ┆ IND          ┆ 2019 ┆ 5.71050201e8 │\n",
      "│ Indonesia    ┆ IND          ┆ 2020 ┆ 5.74606837e8 │\n",
      "│ Indonesia    ┆ IND          ┆ 2021 ┆ 5.78185624e8 │\n",
      "└──────────────┴──────────────┴──────┴──────────────┘\n",
      "Shape: (51, 4)\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Hint: Use .select(), pl.col(), .head(), .slice()\n",
    "\n",
    "# 1. From the COVID dataset, select only 'date', 'country', and 'new_cases' columns\n",
    "covid_selected = covid_df.select([pl.col(\"date\"), pl.col(\"country\"), pl.col(\"new_cases\")])\n",
    "print(\"1. COVID dataset - selected columns:\")\n",
    "print(covid_selected.head())\n",
    "print(f\"Shape: {covid_selected.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 2. From the stocks dataset, select columns whose names contain \"e\"\n",
    "# First, let's see all column names and filter those containing \"e\"\n",
    "stock_columns_with_e = [col for col in stocks_df.columns if \"e\" in col.lower()]\n",
    "print(f\"Stock columns containing 'e': {stock_columns_with_e}\")\n",
    "stocks_selected = stocks_df.select([pl.col(col) for col in stock_columns_with_e])\n",
    "print(\"2. Stocks dataset - columns containing 'e':\")\n",
    "print(stocks_selected.head())\n",
    "print(f\"Shape: {stocks_selected.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 3. Select the first 100 rows from the sales dataset\n",
    "sales_first_100 = sales_df.head(100)\n",
    "print(\"3. Sales dataset - first 100 rows:\")\n",
    "print(sales_first_100.head())  # Show first 5 of the 100\n",
    "print(f\"Shape: {sales_first_100.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 4. Select rows 50-100 from the population dataset (using slice)\n",
    "population_50_100 = population_df.slice(49, 51)  # slice(offset, length) - 49 is 0-indexed for row 50\n",
    "print(\"4. Population dataset - rows 50-100:\")\n",
    "print(population_50_100.head())\n",
    "print(f\"Shape: {population_50_100.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Functions**: Column selection, row subsetting\n",
    "\n",
    "---\n",
    "\n",
    "## PART 2: Filtering and Subsetting Data\n",
    "\n",
    "### Exercise 2.1: Basic Filtering\n",
    "\n",
    "**Business Context**: WHO wants to focus on countries with significant COVID-19 impact.\n",
    "\n",
    "**Tasks**:\n",
    "1. Filter COVID data for countries with more than 1000 new cases on any single day\n",
    "2. Filter stock data for Apple (AAPL) only\n",
    "3. Filter sales data for Technology category products\n",
    "4. Filter population data for countries with more than 100 million people\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COVID data with >1000 new cases on any day:\n",
      "shape: (5, 6)\n",
      "┌────────────┬─────────┬───────────┬────────────┬─────────────┬──────────────┐\n",
      "│ date       ┆ country ┆ new_cases ┆ new_deaths ┆ total_cases ┆ total_deaths │\n",
      "│ ---        ┆ ---     ┆ ---       ┆ ---        ┆ ---         ┆ ---          │\n",
      "│ str        ┆ str     ┆ f64       ┆ f64        ┆ f64         ┆ f64          │\n",
      "╞════════════╪═════════╪═══════════╪════════════╪═════════════╪══════════════╡\n",
      "│ 2020-05-24 ┆ Germany ┆ 1006.0    ┆ 19.0       ┆ 88473.0     ┆ 1691.0       │\n",
      "│ 2020-05-25 ┆ Germany ┆ 1014.0    ┆ 18.0       ┆ 89487.0     ┆ 1709.0       │\n",
      "│ 2020-05-29 ┆ Germany ┆ 1013.0    ┆ 18.0       ┆ 93467.0     ┆ 1787.0       │\n",
      "│ 2020-06-02 ┆ Germany ┆ 1018.0    ┆ 22.0       ┆ 97451.0     ┆ 1864.0       │\n",
      "│ 2020-06-03 ┆ Germany ┆ 1004.0    ┆ 20.0       ┆ 98455.0     ┆ 1884.0       │\n",
      "└────────────┴─────────┴───────────┴────────────┴─────────────┴──────────────┘\n",
      "Shape: (3526, 6)\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "ename": "ColumnNotFoundError",
     "evalue": "Symbol",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mColumnNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# 2. Filter stock data for Apple (AAPL) only\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m apple_stock \u001b[38;5;241m=\u001b[39m \u001b[43mstocks_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSymbol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAAPL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApple (AAPL) stock data:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(apple_stock\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m~/miniconda3/envs/ooc/lib/python3.10/site-packages/polars/dataframe/frame.py:3969\u001b[0m, in \u001b[0;36mDataFrame.filter\u001b[0;34m(self, predicate)\u001b[0m\n\u001b[1;32m   3965\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _check_for_numpy(predicate) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(predicate, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m   3966\u001b[0m     predicate \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mSeries(predicate)\n\u001b[1;32m   3968\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m-> 3969\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43meager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   3970\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/ooc/lib/python3.10/site-packages/polars/utils/deprecation.py:95\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m     92\u001b[0m     _rename_keyword_argument(\n\u001b[1;32m     93\u001b[0m         old_name, new_name, kwargs, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, version\n\u001b[1;32m     94\u001b[0m     )\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ooc/lib/python3.10/site-packages/polars/lazyframe/frame.py:1703\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, no_optimization, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, streaming, **kwargs)\u001b[0m\n\u001b[1;32m   1690\u001b[0m     comm_subplan_elim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1692\u001b[0m ldf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ldf\u001b[38;5;241m.\u001b[39moptimization_toggle(\n\u001b[1;32m   1693\u001b[0m     type_coercion,\n\u001b[1;32m   1694\u001b[0m     predicate_pushdown,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1701\u001b[0m     eager,\n\u001b[1;32m   1702\u001b[0m )\n\u001b[0;32m-> 1703\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mColumnNotFoundError\u001b[0m: Symbol"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Hint: Use .filter(), pl.col()\n",
    "\n",
    "# 1. Filter COVID data for countries with more than 1000 new cases on any single day\n",
    "covid_high_cases = covid_df.filter(pl.col(\"new_cases\") > 1000)\n",
    "print(\"COVID data with >1000 new cases on any day:\")\n",
    "print(covid_high_cases.head())\n",
    "print(f\"Shape: {covid_high_cases.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 2. Filter stock data for Apple (AAPL) only\n",
    "apple_stock = stocks_df.filter(pl.col(\"Symbol\") == \"AAPL\")\n",
    "print(\"Apple (AAPL) stock data:\")\n",
    "print(apple_stock.head())\n",
    "print(f\"Shape: {apple_stock.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 3. Filter sales data for Technology category products\n",
    "tech_sales = sales_df.filter(pl.col(\"Category\") == \"Technology\")\n",
    "print(\"Technology category sales:\")\n",
    "print(tech_sales.head())\n",
    "print(f\"Shape: {tech_sales.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 4. Filter population data for countries with more than 100 million people\n",
    "# Note: Assuming there's a population column, adjust column name as needed\n",
    "high_pop_countries = population_df.filter(pl.col(\"Population\") > 100000000)\n",
    "print(\"Countries with >100M people:\")\n",
    "print(high_pop_countries.head())\n",
    "print(f\"Shape: {high_pop_countries.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Functions**: Filtering with conditions\n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 2.2: Complex Filtering\n",
    "\n",
    "**Business Context**: PrimeTech Capital wants to identify high-volatility tech stocks.\n",
    "\n",
    "**Tasks**:\n",
    "1. Filter stock data where the daily price range (high - low) is greater than $10\n",
    "2. Filter COVID data for dates between \"2020-03-01\" and \"2020-06-01\"\n",
    "3. Filter sales data for orders with discount > 0.15 AND profit > 100\n",
    "4. Sample 500 random rows from the sales dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stocks dataset columns: ['date', 'symbol', 'open', 'high', 'low', 'close', 'volume']\n",
      "Stocks dataset sample:\n",
      "shape: (5, 7)\n",
      "┌────────────┬────────┬────────┬────────┬────────┬────────┬──────────┐\n",
      "│ date       ┆ symbol ┆ open   ┆ high   ┆ low    ┆ close  ┆ volume   │\n",
      "│ ---        ┆ ---    ┆ ---    ┆ ---    ┆ ---    ┆ ---    ┆ ---      │\n",
      "│ str        ┆ str    ┆ f64    ┆ f64    ┆ f64    ┆ f64    ┆ i64      │\n",
      "╞════════════╪════════╪════════╪════════╪════════╪════════╪══════════╡\n",
      "│ 2020-01-01 ┆ AAPL   ┆ 453.31 ┆ 464.79 ┆ 451.66 ┆ 456.22 ┆ 33335151 │\n",
      "│ 2020-01-02 ┆ AAPL   ┆ 449.22 ┆ 452.34 ┆ 443.46 ┆ 450.87 ┆ 18852110 │\n",
      "│ 2020-01-03 ┆ AAPL   ┆ 462.21 ┆ 462.56 ┆ 451.64 ┆ 459.14 ┆ 2285651  │\n",
      "│ 2020-01-06 ┆ AAPL   ┆ 475.14 ┆ 481.87 ┆ 467.84 ┆ 468.79 ┆ 7444385  │\n",
      "│ 2020-01-07 ┆ AAPL   ┆ 468.88 ┆ 468.94 ┆ 464.1  ┆ 466.54 ┆ 44543554 │\n",
      "└────────────┴────────┴────────┴────────┴────────┴────────┴──────────┘\n",
      "\n",
      "==================================================\n",
      "\n",
      "1. Stock data with daily price range > $10:\n",
      "shape: (5, 7)\n",
      "┌────────────┬────────┬────────┬────────┬────────┬────────┬──────────┐\n",
      "│ date       ┆ symbol ┆ open   ┆ high   ┆ low    ┆ close  ┆ volume   │\n",
      "│ ---        ┆ ---    ┆ ---    ┆ ---    ┆ ---    ┆ ---    ┆ ---      │\n",
      "│ str        ┆ str    ┆ f64    ┆ f64    ┆ f64    ┆ f64    ┆ i64      │\n",
      "╞════════════╪════════╪════════╪════════╪════════╪════════╪══════════╡\n",
      "│ 2020-01-01 ┆ AAPL   ┆ 453.31 ┆ 464.79 ┆ 451.66 ┆ 456.22 ┆ 33335151 │\n",
      "│ 2020-01-03 ┆ AAPL   ┆ 462.21 ┆ 462.56 ┆ 451.64 ┆ 459.14 ┆ 2285651  │\n",
      "│ 2020-01-06 ┆ AAPL   ┆ 475.14 ┆ 481.87 ┆ 467.84 ┆ 468.79 ┆ 7444385  │\n",
      "│ 2020-01-08 ┆ AAPL   ┆ 474.98 ┆ 487.74 ┆ 472.73 ┆ 474.37 ┆ 19279245 │\n",
      "│ 2020-01-10 ┆ AAPL   ┆ 493.53 ┆ 503.71 ┆ 489.35 ┆ 493.16 ┆ 32314636 │\n",
      "└────────────┴────────┴────────┴────────┴────────┴────────┴──────────┘\n",
      "Shape: (1333, 7)\n",
      "\n",
      "==================================================\n",
      "\n",
      "2. COVID data between March 1 - June 1, 2020:\n",
      "shape: (5, 6)\n",
      "┌────────────┬───────────────┬───────────┬────────────┬─────────────┬──────────────┐\n",
      "│ date       ┆ country       ┆ new_cases ┆ new_deaths ┆ total_cases ┆ total_deaths │\n",
      "│ ---        ┆ ---           ┆ ---       ┆ ---        ┆ ---         ┆ ---          │\n",
      "│ str        ┆ str           ┆ f64       ┆ f64        ┆ f64         ┆ f64          │\n",
      "╞════════════╪═══════════════╪═══════════╪════════════╪═════════════╪══════════════╡\n",
      "│ 2020-03-01 ┆ United States ┆ 203.0     ┆ 3.0        ┆ 6489.0      ┆ 109.0        │\n",
      "│ 2020-03-02 ┆ United States ┆ 186.0     ┆ 3.0        ┆ 6675.0      ┆ 112.0        │\n",
      "│ 2020-03-03 ┆ United States ┆ 197.0     ┆ 4.0        ┆ 6872.0      ┆ 116.0        │\n",
      "│ 2020-03-04 ┆ United States ┆ 180.0     ┆ 1.0        ┆ 7052.0      ┆ 117.0        │\n",
      "│ 2020-03-05 ┆ United States ┆ 205.0     ┆ 6.0        ┆ 7257.0      ┆ 123.0        │\n",
      "└────────────┴───────────────┴───────────┴────────────┴─────────────┴──────────────┘\n",
      "Shape: (930, 6)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Sales dataset columns: ['order_id', 'order_date', 'ship_date', 'ship_mode', 'customer_id', 'customer_name', 'segment', 'region', 'state', 'category', 'sub_category', 'product_name', 'sales', 'quantity', 'discount', 'profit']\n",
      "3. Sales data with discount > 0.15 AND profit > 100:\n",
      "shape: (5, 16)\n",
      "┌──────────┬────────────┬────────────┬──────────────┬───┬─────────┬──────────┬──────────┬────────┐\n",
      "│ order_id ┆ order_date ┆ ship_date  ┆ ship_mode    ┆ … ┆ sales   ┆ quantity ┆ discount ┆ profit │\n",
      "│ ---      ┆ ---        ┆ ---        ┆ ---          ┆   ┆ ---     ┆ ---      ┆ ---      ┆ ---    │\n",
      "│ str      ┆ str        ┆ str        ┆ str          ┆   ┆ f64     ┆ i64      ┆ f64      ┆ f64    │\n",
      "╞══════════╪════════════╪════════════╪══════════════╪═══╪═════════╪══════════╪══════════╪════════╡\n",
      "│ ORD-1013 ┆ 2021-02-21 ┆ 2021-02-28 ┆ Same Day     ┆ … ┆ 3773.0  ┆ 7        ┆ 0.2      ┆ 324.36 │\n",
      "│ ORD-1015 ┆ 2020-12-04 ┆ 2020-12-17 ┆ Second Class ┆ … ┆ 4713.23 ┆ 8        ┆ 0.25     ┆ 560.02 │\n",
      "│ ORD-1018 ┆ 2021-12-18 ┆ 2021-12-23 ┆ First Class  ┆ … ┆ 5076.78 ┆ 10       ┆ 0.2      ┆ 727.08 │\n",
      "│ ORD-1019 ┆ 2022-08-22 ┆ 2022-08-28 ┆ Same Day     ┆ … ┆ 2530.53 ┆ 8        ┆ 0.25     ┆ 289.54 │\n",
      "│ ORD-1034 ┆ 2020-11-20 ┆ 2020-11-22 ┆ First Class  ┆ … ┆ 2662.85 ┆ 10       ┆ 0.25     ┆ 570.81 │\n",
      "└──────────┴────────────┴────────────┴──────────────┴───┴─────────┴──────────┴──────────┴────────┘\n",
      "Shape: (393, 16)\n",
      "\n",
      "==================================================\n",
      "\n",
      "4. Random sample of 500 rows from sales dataset:\n",
      "shape: (5, 16)\n",
      "┌──────────┬────────────┬────────────┬────────────────┬───┬─────────┬──────────┬──────────┬────────┐\n",
      "│ order_id ┆ order_date ┆ ship_date  ┆ ship_mode      ┆ … ┆ sales   ┆ quantity ┆ discount ┆ profit │\n",
      "│ ---      ┆ ---        ┆ ---        ┆ ---            ┆   ┆ ---     ┆ ---      ┆ ---      ┆ ---    │\n",
      "│ str      ┆ str        ┆ str        ┆ str            ┆   ┆ f64     ┆ i64      ┆ f64      ┆ f64    │\n",
      "╞══════════╪════════════╪════════════╪════════════════╪═══╪═════════╪══════════╪══════════╪════════╡\n",
      "│ ORD-5677 ┆ 2020-11-14 ┆ 2020-11-16 ┆ First Class    ┆ … ┆ 5872.04 ┆ 7        ┆ 0.0      ┆ 979.7  │\n",
      "│ ORD-3898 ┆ 2019-02-26 ┆ 2019-03-08 ┆ Standard Class ┆ … ┆ 1998.25 ┆ 2        ┆ 0.0      ┆ 138.92 │\n",
      "│ ORD-1002 ┆ 2021-02-28 ┆ 2021-03-03 ┆ Same Day       ┆ … ┆ 1309.0  ┆ 9        ┆ 0.0      ┆ 198.07 │\n",
      "│ ORD-4538 ┆ 2022-06-02 ┆ 2022-06-10 ┆ Standard Class ┆ … ┆ 2872.48 ┆ 5        ┆ 0.0      ┆ 174.93 │\n",
      "│ ORD-3893 ┆ 2019-04-14 ┆ 2019-04-18 ┆ Standard Class ┆ … ┆ 3264.89 ┆ 10       ┆ 0.0      ┆ 441.56 │\n",
      "└──────────┴────────────┴────────────┴────────────────┴───┴─────────┴──────────┴──────────┴────────┘\n",
      "Shape: (500, 16)\n",
      "Sample contains rows from various parts of the dataset\n",
      "Original dataset has 5000 rows\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Hint: Use .filter() with multiple conditions, .sample()\n",
    "\n",
    "# First, let's check the actual column names in stocks dataset\n",
    "print(\"Stocks dataset columns:\", stocks_df.columns)\n",
    "print(\"Stocks dataset sample:\")\n",
    "print(stocks_df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 1. Filter stock data where the daily price range (high - low) is greater than $10\n",
    "# Using the correct column names from the dataset\n",
    "high_volatility_stocks = stocks_df.filter((pl.col(\"high\") - pl.col(\"low\")) > 10)\n",
    "print(\"1. Stock data with daily price range > $10:\")\n",
    "print(high_volatility_stocks.head())\n",
    "print(f\"Shape: {high_volatility_stocks.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 2. Filter COVID data for dates between \"2020-03-01\" and \"2020-06-01\"\n",
    "covid_march_june = covid_df.filter(\n",
    "    (pl.col(\"date\") >= \"2020-03-01\") & (pl.col(\"date\") <= \"2020-06-01\")\n",
    ")\n",
    "print(\"2. COVID data between March 1 - June 1, 2020:\")\n",
    "print(covid_march_june.head())\n",
    "print(f\"Shape: {covid_march_june.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 3. Filter sales data for orders with discount > 0.15 AND profit > 100\n",
    "# First check sales dataset columns\n",
    "print(\"Sales dataset columns:\", sales_df.columns)\n",
    "high_discount_profitable = sales_df.filter(\n",
    "    (pl.col(\"discount\") > 0.15) & (pl.col(\"profit\") > 100)\n",
    ")\n",
    "print(\"3. Sales data with discount > 0.15 AND profit > 100:\")\n",
    "print(high_discount_profitable.head())\n",
    "print(f\"Shape: {high_discount_profitable.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 4. Sample 500 random rows from the sales dataset\n",
    "sales_sample = sales_df.sample(500, seed=42)  # Using seed for reproducible results\n",
    "print(\"4. Random sample of 500 rows from sales dataset:\")\n",
    "print(sales_sample.head())\n",
    "print(f\"Shape: {sales_sample.shape}\")\n",
    "\n",
    "# Additional info: Show the range of row indices to confirm randomness\n",
    "print(f\"Sample contains rows from various parts of the dataset\")\n",
    "print(f\"Original dataset has {sales_df.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Functions**: Complex filtering, sampling\n",
    "\n",
    "---\n",
    "\n",
    "## PART 3: Grouping and Aggregation\n",
    "\n",
    "### Exercise 3.1: Basic Grouping\n",
    "\n",
    "**Business Context**: SuperMart wants to understand sales performance by different dimensions.\n",
    "\n",
    "**Tasks**:\n",
    "1. Group sales data by 'region' and calculate total sales\n",
    "2. Group COVID data by 'country' and find maximum daily cases\n",
    "3. Group stock data by 'symbol' and calculate average closing price\n",
    "4. Count the number of records in each population dataset by year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Total sales by region:\n",
      "shape: (4, 2)\n",
      "┌─────────┬─────────────┐\n",
      "│ region  ┆ total_sales │\n",
      "│ ---     ┆ ---         │\n",
      "│ str     ┆ f64         │\n",
      "╞═════════╪═════════════╡\n",
      "│ Central ┆ 3.4162e6    │\n",
      "│ East    ┆ 3.4862e6    │\n",
      "│ South   ┆ 3.3661e6    │\n",
      "│ West    ┆ 3.2890e6    │\n",
      "└─────────┴─────────────┘\n",
      "\n",
      "==================================================\n",
      "\n",
      "2. Maximum daily COVID cases by country:\n",
      "shape: (10, 2)\n",
      "┌────────────────┬─────────────────┐\n",
      "│ country        ┆ max_daily_cases │\n",
      "│ ---            ┆ ---             │\n",
      "│ str            ┆ f64             │\n",
      "╞════════════════╪═════════════════╡\n",
      "│ Japan          ┆ 2037.0          │\n",
      "│ United Kingdom ┆ 892.0           │\n",
      "│ Germany        ┆ 3021.0          │\n",
      "│ Italy          ┆ 482.0           │\n",
      "│ …              ┆ …               │\n",
      "│ Spain          ┆ 3074.0          │\n",
      "│ South Korea    ┆ 2824.0          │\n",
      "│ United States  ┆ 907.0           │\n",
      "│ France         ┆ 2727.0          │\n",
      "└────────────────┴─────────────────┘\n",
      "\n",
      "==================================================\n",
      "\n",
      "3. Average closing price by stock symbol:\n",
      "shape: (8, 2)\n",
      "┌────────┬─────────────────┐\n",
      "│ symbol ┆ avg_close_price │\n",
      "│ ---    ┆ ---             │\n",
      "│ str    ┆ f64             │\n",
      "╞════════╪═════════════════╡\n",
      "│ MSFT   ┆ 111.355781      │\n",
      "│ NFLX   ┆ 379.710019      │\n",
      "│ TSLA   ┆ 208.406596      │\n",
      "│ NVDA   ┆ 215.474094      │\n",
      "│ AMZN   ┆ 135.692723      │\n",
      "│ GOOGL  ┆ 129.304583      │\n",
      "│ AAPL   ┆ 458.908245      │\n",
      "│ META   ┆ 688.574276      │\n",
      "└────────┴─────────────────┘\n",
      "\n",
      "==================================================\n",
      "\n",
      "4. Number of records in population dataset by year:\n",
      "shape: (14, 2)\n",
      "┌──────┬──────────────┐\n",
      "│ year ┆ record_count │\n",
      "│ ---  ┆ ---          │\n",
      "│ i64  ┆ u32          │\n",
      "╞══════╪══════════════╡\n",
      "│ 2010 ┆ 10           │\n",
      "│ 2022 ┆ 10           │\n",
      "│ 2021 ┆ 10           │\n",
      "│ 2016 ┆ 10           │\n",
      "│ …    ┆ …            │\n",
      "│ 2018 ┆ 10           │\n",
      "│ 2019 ┆ 10           │\n",
      "│ 2014 ┆ 10           │\n",
      "│ 2013 ┆ 10           │\n",
      "└──────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Hint: Use .group_by(), .agg(), pl.sum(), pl.max(), pl.mean(), pl.count()\n",
    "\n",
    "# 1. Group sales data by 'region' and calculate total sales\n",
    "sales_by_region = sales_df.group_by(\"region\").agg(pl.sum(\"sales\").alias(\"total_sales\"))\n",
    "print(\"1. Total sales by region:\")\n",
    "print(sales_by_region)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 2. Group COVID data by 'country' and find maximum daily cases\n",
    "max_cases_by_country = covid_df.group_by(\"country\").agg(pl.max(\"new_cases\").alias(\"max_daily_cases\"))\n",
    "print(\"2. Maximum daily COVID cases by country:\")\n",
    "print(max_cases_by_country)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 3. Group stock data by 'symbol' and calculate average closing price\n",
    "avg_close_by_symbol = stocks_df.group_by(\"symbol\").agg(pl.mean(\"close\").alias(\"avg_close_price\"))\n",
    "print(\"3. Average closing price by stock symbol:\")\n",
    "print(avg_close_by_symbol)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 4. Count the number of records in each population dataset by year\n",
    "count_by_year = population_df.group_by(\"year\").agg(pl.count().alias(\"record_count\"))\n",
    "print(\"4. Number of records in population dataset by year:\")\n",
    "print(count_by_year)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Functions**: Basic grouping and aggregation\n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 3.2: Advanced Aggregations\n",
    "\n",
    "**Business Context**: WHO needs comprehensive statistics for their pandemic response.\n",
    "\n",
    "**Tasks**:\n",
    "1. For each country in COVID data, calculate:\n",
    "   - Total cases, maximum daily cases, average daily cases\n",
    "   - Standard deviation of daily cases, median daily cases\n",
    "2. For each stock symbol, calculate:\n",
    "   - Mean closing price, min/max prices, price volatility (std dev)\n",
    "3. For sales data by category, calculate:\n",
    "   - Total sales, total profit, average discount, profit margin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. COVID stats by country:\n",
      "shape: (10, 6)\n",
      "┌────────────────┬─────────────┬────────────────┬────────────────┬────────────────┬────────────────┐\n",
      "│ country        ┆ total_cases ┆ max_daily_case ┆ avg_daily_case ┆ std_daily_case ┆ median_daily_c │\n",
      "│ ---            ┆ ---         ┆ s              ┆ s              ┆ s              ┆ ases           │\n",
      "│ str            ┆ f64         ┆ ---            ┆ ---            ┆ ---            ┆ ---            │\n",
      "│                ┆             ┆ f64            ┆ f64            ┆ f64            ┆ f64            │\n",
      "╞════════════════╪═════════════╪════════════════╪════════════════╪════════════════╪════════════════╡\n",
      "│ Australia      ┆ 724076.0    ┆ 1433.0         ┆ 506.346853     ┆ 371.728761     ┆ 423.0          │\n",
      "│ France         ┆ 1.369519e6  ┆ 2727.0         ┆ 957.036338     ┆ 724.059647     ┆ 810.0          │\n",
      "│ Spain          ┆ 1.534921e6  ┆ 3074.0         ┆ 1078.651441    ┆ 818.942406     ┆ 897.0          │\n",
      "│ United States  ┆ 466946.0    ┆ 907.0          ┆ 324.945024     ┆ 232.825871     ┆ 272.0          │\n",
      "│ …              ┆ …           ┆ …              ┆ …              ┆ …              ┆ …              │\n",
      "│ South Korea    ┆ 1.423163e6  ┆ 2824.0         ┆ 989.682197     ┆ 748.774874     ┆ 839.5          │\n",
      "│ Canada         ┆ 1.426041e6  ┆ 2827.0         ┆ 992.373695     ┆ 750.364389     ┆ 843.0          │\n",
      "│ United Kingdom ┆ 458228.0    ┆ 892.0          ┆ 318.878219     ┆ 229.024502     ┆ 267.0          │\n",
      "│ Germany        ┆ 1.50859e6   ┆ 3021.0         ┆ 1054.958042    ┆ 803.425935     ┆ 885.5          │\n",
      "└────────────────┴─────────────┴────────────────┴────────────────┴────────────────┴────────────────┘\n",
      "\n",
      "==================================================\n",
      "\n",
      "2. Stock stats by symbol:\n",
      "shape: (8, 5)\n",
      "┌────────┬────────────┬───────────┬───────────┬────────────┐\n",
      "│ symbol ┆ mean_close ┆ min_close ┆ max_close ┆ volatility │\n",
      "│ ---    ┆ ---        ┆ ---       ┆ ---       ┆ ---        │\n",
      "│ str    ┆ f64        ┆ f64       ┆ f64       ┆ f64        │\n",
      "╞════════╪════════════╪═══════════╪═══════════╪════════════╡\n",
      "│ META   ┆ 688.574276 ┆ 308.86    ┆ 1216.14   ┆ 285.45803  │\n",
      "│ MSFT   ┆ 111.355781 ┆ 52.69     ┆ 163.74    ┆ 24.28893   │\n",
      "│ NVDA   ┆ 215.474094 ┆ 107.91    ┆ 523.38    ┆ 107.067716 │\n",
      "│ AAPL   ┆ 458.908245 ┆ 312.87    ┆ 634.74    ┆ 58.025483  │\n",
      "│ AMZN   ┆ 135.692723 ┆ 86.76     ┆ 188.38    ┆ 22.860348  │\n",
      "│ TSLA   ┆ 208.406596 ┆ 122.09    ┆ 372.23    ┆ 53.265844  │\n",
      "│ GOOGL  ┆ 129.304583 ┆ 87.07     ┆ 188.97    ┆ 23.113118  │\n",
      "│ NFLX   ┆ 379.710019 ┆ 268.98    ┆ 513.78    ┆ 50.092848  │\n",
      "└────────┴────────────┴───────────┴───────────┴────────────┘\n",
      "\n",
      "==================================================\n",
      "\n",
      "3. Sales stats by category:\n",
      "shape: (3, 5)\n",
      "┌─────────────────┬─────────────┬──────────────┬──────────────┬───────────────┐\n",
      "│ category        ┆ total_sales ┆ total_profit ┆ avg_discount ┆ profit_margin │\n",
      "│ ---             ┆ ---         ┆ ---          ┆ ---          ┆ ---           │\n",
      "│ str             ┆ f64         ┆ f64          ┆ f64          ┆ f64           │\n",
      "╞═════════════════╪═════════════╪══════════════╪══════════════╪═══════════════╡\n",
      "│ Furniture       ┆ 4.3993e6    ┆ 353200.45    ┆ 0.043829     ┆ 0.080286      │\n",
      "│ Office Supplies ┆ 4.5406e6    ┆ 549391.31    ┆ 0.04235      ┆ 0.120997      │\n",
      "│ Technology      ┆ 4.6177e6    ┆ 679643.37    ┆ 0.041479     ┆ 0.147181      │\n",
      "└─────────────────┴─────────────┴──────────────┴──────────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Hint: Use .agg() with multiple aggregation functions\n",
    "\n",
    "# 1. For each country in COVID data\n",
    "covid_stats = covid_df.group_by(\"country\").agg([\n",
    "    pl.sum(\"new_cases\").alias(\"total_cases\"),\n",
    "    pl.max(\"new_cases\").alias(\"max_daily_cases\"),\n",
    "    pl.mean(\"new_cases\").alias(\"avg_daily_cases\"),\n",
    "    pl.std(\"new_cases\").alias(\"std_daily_cases\"),\n",
    "    pl.median(\"new_cases\").alias(\"median_daily_cases\")\n",
    "])\n",
    "print(\"1. COVID stats by country:\")\n",
    "print(covid_stats)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 2. For each stock symbol\n",
    "stock_stats = stocks_df.group_by(\"symbol\").agg([\n",
    "    pl.mean(\"close\").alias(\"mean_close\"),\n",
    "    pl.min(\"close\").alias(\"min_close\"),\n",
    "    pl.max(\"close\").alias(\"max_close\"),\n",
    "    pl.std(\"close\").alias(\"volatility\")\n",
    "])\n",
    "print(\"2. Stock stats by symbol:\")\n",
    "print(stock_stats)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 3. For sales data by category\n",
    "sales_stats = sales_df.group_by(\"category\").agg([\n",
    "    pl.sum(\"sales\").alias(\"total_sales\"),\n",
    "    pl.sum(\"profit\").alias(\"total_profit\"),\n",
    "    pl.mean(\"discount\").alias(\"avg_discount\"),\n",
    "    (pl.sum(\"profit\") / pl.sum(\"sales\")).alias(\"profit_margin\")\n",
    "])\n",
    "print(\"3. Sales stats by category:\")\n",
    "print(sales_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Functions**: Multiple aggregations, statistical functions\n",
    "\n",
    "---\n",
    "\n",
    "## PART 4: Time Series Analysis\n",
    "\n",
    "### Exercise 4.1: Date Operations\n",
    "\n",
    "**Business Context**: Analyzing trends over time requires proper date handling.\n",
    "\n",
    "**Tasks**:\n",
    "1. Convert date columns to datetime format in all relevant datasets\n",
    "2. Extract year, month, and day of week from COVID data dates\n",
    "3. Filter stock data for trading days in 2022 only\n",
    "4. Calculate the number of days between order_date and ship_date in sales data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: Use pl.col().str.strptime(), .dt.year(), .dt.month(), .dt.weekday()\n",
    "\n",
    "# 1. Convert date columns to datetime format in all relevant datasets\n",
    "covid_df = covid_df.with_columns([\n",
    "    pl.col(\"date\").str.strptime(pl.Date, \"%Y-%m-%d\").alias(\"date\")\n",
    "])\n",
    "stocks_df = stocks_df.with_columns([\n",
    "    pl.col(\"date\").str.strptime(pl.Date, \"%Y-%m-%d\").alias(\"date\")\n",
    "])\n",
    "sales_df = sales_df.with_columns([\n",
    "    pl.col(\"order_date\").str.strptime(pl.Date, \"%Y-%m-%d\").alias(\"order_date\"),\n",
    "    pl.col(\"ship_date\").str.strptime(pl.Date, \"%Y-%m-%d\").alias(\"ship_date\")\n",
    "])\n",
    "\n",
    "print(\"1. Date columns converted to datetime format.\")\n",
    "\n",
    "# 2. Extract year, month, and day of week from COVID data dates\n",
    "covid_dates = covid_df.with_columns([\n",
    "    pl.col(\"date\").dt.year().alias(\"year\"),\n",
    "    pl.col(\"date\").dt.month().alias(\"month\"),\n",
    "    pl.col(\"date\").dt.weekday().alias(\"weekday\")\n",
    "])\n",
    "print(\"2. COVID data with year, month, weekday columns:\")\n",
    "print(covid_dates.select([\"date\", \"year\", \"month\", \"weekday\", \"country\", \"new_cases\"]).head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 3. Filter stock data for trading days in 2022 only\n",
    "stocks_2022 = stocks_df.filter(pl.col(\"date\").dt.year() == 2022)\n",
    "print(\"3. Stock data for trading days in 2022:\")\n",
    "print(stocks_2022.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 4. Calculate the number of days between order_date and ship_date in sales data\n",
    "sales_with_days = sales_df.with_columns([\n",
    "    (pl.col(\"ship_date\") - pl.col(\"order_date\")).dt.days().alias(\"days_to_ship\")\n",
    "])\n",
    "print(\"4. Sales data with days between order and ship date:\")\n",
    "print(sales_with_days.select([\"order_date\", \"ship_date\", \"days_to_ship\"]).head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Functions**: Date parsing and manipulation\n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 4.2: Rolling Functions\n",
    "\n",
    "**Business Context**: PrimeTech Capital wants to smooth out stock price volatility with moving averages.\n",
    "\n",
    "**Tasks**:\n",
    "1. Calculate 7-day rolling average of new COVID cases for each country\n",
    "2. Calculate 30-day rolling average of stock closing prices for each symbol\n",
    "3. Calculate 7-day rolling maximum and minimum for stock prices\n",
    "4. Calculate 14-day rolling sum of sales by region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: Use .rolling_mean(), .rolling_max(), .rolling_min(), .rolling_sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Functions**: Rolling calculations\n",
    "\n",
    "---\n",
    "\n",
    "## PART 5: Window Functions\n",
    "\n",
    "### Exercise 5.1: Window Calculations\n",
    "\n",
    "**Business Context**: Compare performance within groups without losing individual records.\n",
    "\n",
    "**Tasks**:\n",
    "1. For each country, calculate the percentage of total global cases\n",
    "2. Rank stock symbols by their average closing price\n",
    "3. Calculate each region's share of total sales\n",
    "4. Find each customer's total spending and rank them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: Use .over(), .rank(), window functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Functions**: Window functions, ranking\n",
    "\n",
    "---\n",
    "\n",
    "## PART 6: Handling Missing Data\n",
    "\n",
    "### Exercise 6.1: Missing Data Detection and Treatment\n",
    "\n",
    "**Business Context**: Real-world data often has missing values that need handling.\n",
    "\n",
    "**Tasks**:\n",
    "1. Find all missing values in each dataset\n",
    "2. Drop rows with any missing values from COVID data\n",
    "3. Fill missing population values with the forward fill strategy\n",
    "4. Replace missing values with the column mean for numeric columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: Use .drop_nulls(), .fill_null(), .is_null()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Functions**: Missing data handling\n",
    "\n",
    "---\n",
    "\n",
    "## PART 7: Creating New Columns\n",
    "\n",
    "### Exercise 7.1: Column Transformations\n",
    "\n",
    "**Business Context**: Create new metrics and calculated fields for analysis.\n",
    "\n",
    "**Tasks**:\n",
    "1. Create a 'daily_volatility' column for stocks (high - low) / close\n",
    "2. Create a 'case_fatality_rate' column for COVID data (deaths/cases)\n",
    "3. Create a 'profit_margin' column for sales data (profit/sales)\n",
    "4. Add a row count column to identify each record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: Use .with_columns(), arithmetic operations, .with_row_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Functions**: Column creation and transformation\n",
    "\n",
    "---\n",
    "\n",
    "## PART 8: Reshaping Data\n",
    "\n",
    "### Exercise 8.1: Pivoting and Melting\n",
    "\n",
    "**Business Context**: Different analysis requires different data layouts.\n",
    "\n",
    "**Tasks**:\n",
    "1. Pivot COVID data to have countries as columns and dates as rows (for new_cases)\n",
    "2. Melt stock data to have 'price_type' (open, high, low, close) and 'price' columns\n",
    "3. Pivot sales data to show total sales by region and category\n",
    "4. Concatenate all stock data with company information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: Use .pivot(), .melt(), pl.concat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Functions**: Data reshaping\n",
    "\n",
    "---\n",
    "\n",
    "## PART 9: Joining Datasets\n",
    "\n",
    "### Exercise 9.1: Data Joins\n",
    "\n",
    "**Business Context**: Combine datasets to get comprehensive insights.\n",
    "\n",
    "**Tasks**:\n",
    "1. Inner join stock data with company information on 'symbol'\n",
    "2. Left join sales data with a customer information table (you'll need to create a simple one)\n",
    "3. Anti join to find stocks that don't have company information\n",
    "4. Create a summary table by joining aggregated data from multiple sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: Use .join() with different how parameters: \"inner\", \"left\", \"anti\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Functions**: Various types of joins\n",
    "\n",
    "---\n",
    "\n",
    "## PART 10: Advanced Analytics\n",
    "\n",
    "### Exercise 10.1: Business Intelligence Queries\n",
    "\n",
    "**Business Context**: Answer complex business questions that combine multiple techniques.\n",
    "\n",
    "**Tasks**:\n",
    "\n",
    "1. **COVID Impact Analysis**: Find the top 5 countries with the highest peak daily cases and their total death count\n",
    "\n",
    "2. **Stock Performance Ranking**: Rank tech stocks by their return (latest price vs first price) and volatility\n",
    "\n",
    "3. **Sales Trend Analysis**: Calculate month-over-month sales growth by region\n",
    "\n",
    "4. **Market Opportunity Analysis**: Identify countries with growing populations but low technology adoption (you'll need to create a proxy metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# This requires combining multiple techniques learned above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Functions**: Complex queries combining multiple operations\n",
    "\n",
    "---\n",
    "\n",
    "## PART 11: Final Challenge Project\n",
    "\n",
    "### Business Case: Multi-Client Analytics Dashboard\n",
    "\n",
    "**Scenario**: You need to create a comprehensive analytics summary for all four clients.\n",
    "\n",
    "**Deliverables**:\n",
    "1. **Executive Summary Table**: Key metrics for each dataset\n",
    "2. **Trend Analysis**: Monthly trends for all time series data\n",
    "3. **Performance Rankings**: Top performers in each category\n",
    "4. **Risk Assessment**: Identify volatile stocks, countries with concerning COVID trends\n",
    "5. **Growth Opportunities**: Regions/countries with best growth potential\n",
    "\n",
    "**Requirements**:\n",
    "- Use at least 10 different Polars functions\n",
    "- Join at least 2 datasets\n",
    "- Include rolling calculations\n",
    "- Handle missing data appropriately\n",
    "- Create meaningful new columns\n",
    "- Provide business insights with each analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your comprehensive solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Function Reference Summary\n",
    "\n",
    "By completing this exercise, you will have practiced these Polars functions:\n",
    "\n",
    "**Data Loading & Inspection**:\n",
    "- `pl.read_csv()`, `.shape`, `.head()`, `.describe()`\n",
    "\n",
    "**Selecting & Subsetting**:\n",
    "- `.select()`, `pl.col()`, `.filter()`, `.sample()`, `.head()`, `.tail()`\n",
    "\n",
    "**Grouping & Aggregation**:\n",
    "- `.group_by()`, `.agg()`, `pl.sum()`, `pl.mean()`, `pl.max()`, `pl.min()`, `pl.count()`\n",
    "\n",
    "**Time Series**:\n",
    "- `.rolling_mean()`, `.rolling_max()`, `.rolling_sum()`, date operations\n",
    "\n",
    "**Window Functions**:\n",
    "- `.over()`, `.rank()`, window calculations\n",
    "\n",
    "**Missing Data**:\n",
    "- `.drop_nulls()`, `.fill_null()`, `.is_null()`\n",
    "\n",
    "**Column Operations**:\n",
    "- `.with_columns()`, `.with_row_count()`, `.rename()`, `.drop()`\n",
    "\n",
    "**Reshaping**:\n",
    "- `.pivot()`, `.melt()`, `pl.concat()`, `.sort()`\n",
    "\n",
    "**Joining**:\n",
    "- `.join()` with various modes (inner, left, outer, anti)\n",
    "\n",
    "---\n",
    "\n",
    "## Tips for Success\n",
    "\n",
    "1. **Start Simple**: Begin with basic operations before combining complex functions\n",
    "2. **Check Your Data**: Always inspect results to ensure they make business sense\n",
    "3. **Use Method Chaining**: Polars allows elegant chaining of operations\n",
    "4. **Handle Edge Cases**: Consider missing data and edge cases in your analysis\n",
    "5. **Document Your Work**: Add comments explaining your business logic\n",
    "\n",
    "Good luck with your analysis!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ooc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
